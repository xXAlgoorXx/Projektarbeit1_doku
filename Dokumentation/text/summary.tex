\chapter*{Summary}
Hexagon AB is a global leader in digitization technology, specializing in measurement and positioning systems.  
The company's laser scanning devices generate point cloud data of the environment and capture images through additional cameras integrated into their scanners.  
The objective of this project is to work towards integrating enhanced scene understanding capabilities into the scanning application's edge devices.

A key part of this project involved conducting a market analysis for hardware accelerators, preferably with M.2 slot capabilities.  
The analysis concluded that Hailo produces the most suitable product currently available, excelling in terms of availability, power consumption, and computing performance.

Hailo is a company that develops hardware accelerators.  
In collaboration with Raspberry Pi, Hailo has created a board equipped with an M.2 slot, compatible with a Raspberry Pi HAT.  
This integration allows neural networks to run on the Raspberry Pi, showcasing the efficiency of hardware accelerators in enabling advanced computing tasks.\hfill\break

In a previous study by Lia Winkler, it was determined that CLIP demonstrated the greatest capacity to fulfill the task at hand.  
\acrfull{clip} is a model designed to assess how well given text prompts align with an image.  
The model comprises a vision encoder and a text encoder, which output high-dimensional vectors.  
The similarity between text and image is calculated using the scaled dot product of these vectors.  

The evaluation of Winkler's work was conducted on a dataset provided by Hexagon, consisting of panorama images.  
These images are divided into five classes: indoor architectural, indoor construction, outdoor construction, outdoor urban, and forest.  
For optimal results, Winkler identified that dividing the images into patches, classifying each patch, and determining the overall class via majority voting yielded the best performance.  

Additionally, Winkler highlighted TinyCLIP in her reportâ€”a version of CLIP with a significantly reduced parameter count while maintaining similar levels of accuracy. \hfill\break

The goal of this project is to implement CLIP and TinyCLIP on Hailo hardware.  
Hailo provides software called the \acrfull{dfc}, which compiles neural networks by quantizing them into a format executable on Hailo hardware.  

However, a significant limitation is that the \acrshort{dfc} currently cannot compile neural networks utilizing transformer architectures.  
This constraint influenced the implementation on the Raspberry Pi.  
The text encoders of CLIP are always transformer-based, while vision encoders are typically vision transformers but can also be implemented as ResNets.  

To overcome this limitation, text encodings must be pre-calculated, saved, and uploaded to the Raspberry Pi.  
On the Raspberry Pi, only ResNets can be used as visual encoders.  
During the compilation of the ResNets, another limitation was identified: due to dimensional constraints on the Hailo hardware, the ResNets had to be divided into two parts.  
The first part is compiled with the \acrshort{dfc} and executed on the hardware accelerator, while the second part runs on the Raspberry Pi's CPU.  

This solution achieved intermediate results.  
To evaluate the accuracy, the same networks were tested on a PC for comparison.  
Initial results revealed a significant decline in accuracy after quantization, with the decline being most pronounced for TinyCLIP models.\hfill\break

To mitigate accuracy loss in quantized models, several steps were taken:  
\begin{enumerate}
    \item  \textbf{Reducing Quantization Levels:}The \acrshort{dfc} allows for adjusting quantization levels.  
    However, due to the lack of a GPU, the process was extremely time-consuming, and an alternative approach was pursued.
    \item \textbf{Revising the Network Split:}The placement of the cut that divides the vision encoder was adjusted.  
    The cut was positioned such that only operations robust to quantization, such as basic convolutions, were included in the first part.  
    Operations sensitive to quantization, such as large matrix multiplications, were allocated to the second part.  
    This adjustment improved accuracy for most models, though not for TinyCLIP.
    \item \textbf{Threshold Adjustment for Binary Class Cases:}The threshold for binary classification was fine-tuned to enhance performance. 
\end{enumerate}

As a result of these optimizations, the RN101 network achieved the best accuracy among the compiled models.  
This finding highlights an important conclusion: the quantization performance of a model depends significantly on the network's width.  
Among the networks compatible with the Hailo hardware, RN101 had the largest width, explaining its superior results.  
Conversely, TinyCLIP's poor accuracy can be attributed to its reduced width, a design trade-off made to minimize parameters.  
This reduction adversely impacts its quantization performance.


\subsection*{Self assessment}
In this work the capabilities of the Hailo hardware accelerator and its software were explored.
The project went a bit of course when the first problem occured where ResNets weren't able to compile.

The communication with Hailo were only beneficial to a cetrain degree.
