\chapter{Literature research}

This Literature research studied relevant papers in the field of scene understanding
and papers which analyse the reduction of neural networks regarding their parameter count and interferance time.
State of the art is to use deep learning models for scene understanding tasks.
The goal of to discover the semantic information within a given scene, which is the base for many applicaitions such as surveillance, autonomous driving, traffic savety, vision-guided mobile navigation and many more.
The term gains a lot of relevantcy because of the rapid evolution of neural networks over the last couple years.

Most of the papers found online tackel the topic of autonomous driving\cite{sceneunderstandingautdriving1}.
In early research \acrfull{cnn}\cite{SegNet} were mostly used for this task.
With the introduction of the transformer \cite{attentionisallyouneed} many researchers moved on to this new arcitecture.
Soon multi-modal networks like CLIP\cite{clip} and ALIGN\cite{ALIGN} came up.
These networks use a text- and image-encoder to learn and predict relations between image and text pairs.
These models are pretrained.
This allows a user to finetune them to better fit the networks to excecute a specific task.

In addition it could be usefull to segment a scene to obeserve specific objects in a image.
For this case a foundational model like \Acrfull{sam}\cite{sam} could be used to preprocess a image.

Because of knowledge distillation\cite{knowledgedistillation} the size of these networks can be reduced significant while still maintaining their function.
TinyCLIP\cite{tinyclip} is an example where the orginial network is reduced by 75\%.
This reduction allows it to use them on restricted platforms and to compute data on the edge.

