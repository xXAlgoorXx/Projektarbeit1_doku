% 
% references.bib 
% 
% 
% (c) 2024 Lukas Sch√∂pf
% 
@misc{clip,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}

@InProceedings{tinyclip,
    title     = {TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance},
    author    = {Wu, Kan and Peng, Houwen and Zhou, Zhenghong and Xiao, Bin and Liu, Mengchen and Yuan, Lu and Xuan, Hong and Valenzuela, Michael and Chen, Xi (Stephen) and Wang, Xinggang and Chao, Hongyang and Hu, Han},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {21970-21980}
}

@online{openai,
  author = {OpenAI},
  url = {https://openai.com},
  urldate = {2024-09-20}
}

@misc{attentionisallyouneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@Article{sceneunderstandingautdriving1,
AUTHOR = {Guo, Zhiyang and Huang, Yingping and Hu, Xing and Wei, Hongjian and Zhao, Baigan},
TITLE = {A Survey on Deep Learning Based Approaches for Scene Understanding in Autonomous Driving},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {471},
URL = {https://www.mdpi.com/2079-9292/10/4/471},
ISSN = {2079-9292},
ABSTRACT = {As a prerequisite for autonomous driving, scene understanding has attracted extensive research. With the rise of the convolutional neural network (CNN)-based deep learning technique, research on scene understanding has achieved significant progress. This paper aims to provide a comprehensive survey of deep learning-based approaches for scene understanding in autonomous driving. We categorize these works into four work streams, including object detection, full scene semantic segmentation, instance segmentation, and lane line segmentation. We discuss and analyze these works according to their characteristics, advantages and disadvantages, and basic frameworks. We also summarize the benchmark datasets and evaluation criteria used in the research community and make a performance comparison of some of the latest works. Lastly, we summarize the review work and provide a discussion on the future challenges of the research domain.},
DOI = {10.3390/electronics10040471}
}

@online{hexagon,
  author = {Hexagon AB},
  url = {https://hexagon.com/},
  urldate = {2024-09-20}
}

@ARTICLE{SegNet,
  author={Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation}, 
  year={2017},
  volume={39},
  number={12},
  pages={2481-2495},
  keywords={Decoding;Neural networks;Training;Computer architecture;Image segmentation;Semantics;Convolutional codes;Deep convolutional neural networks;semantic pixel-wise segmentation;indoor scenes;road scenes;encoder;decoder;pooling;upsampling},
  doi={10.1109/TPAMI.2016.2644615}
}
