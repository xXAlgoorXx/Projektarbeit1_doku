%
% Abstract.tex
%
% (c) 2024 Lukas Schöpf, OST Ostschweizer Fachhochschule
%

\chapter*{Abstract}

Hexagon AB, a leader in digitization technology, focuses on integrating advanced scene understanding capabilities into edge devices for its scanning applications.
This project evaluated the use of hardware accelerators, identifying Hailo's products as the most suitable due to their availability, power efficiency, and computational performance.
By using Hailo's M.2 enabled hardware, neural networks can be efficiently run on Raspberry Pi.\hfill\break 


The study builds on previous work by Lia Winkler, who demonstrated that CLIP, a model for aligning text and images, is well-suited for scene classification tasks.
Her best practice involved dividing panoramic images into patches and classifying them via majority voting, achieving strong results.
TinyCLIP, a lightweight version of CLIP, was also mentioned for its reduced parameter count and efficiency.
The core of the project centered around implementing the CLIP and TinyCLIP models on Hailo hardware to enable efficient scene understanding.
CLIP, a neural network model for assessing the alignment of text prompts with images, demonstrated strong performance in prior research.

Due to limitations in the Hailo platform's ability to compile transformer-based architectures, per-calculated text embeddings were used, and ResNets, a special CNN architecture, were employed as vision encoders.
Challenges arose in maintaining model accuracy after quantization, particularly for models with a lower parameter count.
Various strategies were attempted to mitigate accuracy loss, such as adjusting quantization levels, reworking the network split, and fine-tuning classification thresholds.
However, only the adjusted thresholds showed a slight improvement in some models.\hfill\break 

The results indicated that model accuracy post-quantization is highly dependent on the network’s parameter count. 
Interestingly, TinyCLIP-30M, with fewer parameters, showed better post-quantization accuracy than the larger RN50 model, suggesting that TinyCLIP's optimisation effectively identifies the most important model weights. 
    
	